{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Salary for Candidate (a): 89812.2\n",
      "Predicted Salary for Candidate (b): 120024.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(row1, row2):\n",
    "    \"\"\"Calculate the Euclidean distance between two vectors.\"\"\"\n",
    "    distance = np.sqrt(np.sum((row1 - row2) ** 2))\n",
    "    return distance\n",
    "\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    \"\"\"Get the nearest neighbors for a test instance.\"\"\"\n",
    "    distances = []\n",
    "    for index, train_row in train.iterrows():\n",
    "        dist = euclidean_distance(test_row, train_row[:-1])\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = distances[:num_neighbors]\n",
    "    return [neighbor[0] for neighbor in neighbors]\n",
    "\n",
    "def predict_regression(train, test_row, num_neighbors):\n",
    "    \"\"\"Make a prediction with neighbors.\"\"\"\n",
    "    neighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "    output_values = [neighbor[-1] for neighbor in neighbors]\n",
    "    prediction = np.mean(output_values)\n",
    "    return prediction\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('C:/MyFiles/Notes/4th Semester/UCS411 - Artificial Intelligence/Lab Assignments/lab/Salary_Prediction_Dataset.csv')\n",
    "\n",
    "# Define features and target\n",
    "X = df[['Experience', 'Written_Score', 'Interview_Score']]\n",
    "y = df['Salary']\n",
    "train_data = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Example test data\n",
    "test_data = np.array([5, 8, 10])  # Candidate (a)\n",
    "test_data2 = np.array([8, 7, 6])  # Candidate (b)\n",
    "\n",
    "# Predict salary using a K value\n",
    "K = 5\n",
    "prediction1 = predict_regression(train_data, test_data, K)\n",
    "prediction2 = predict_regression(train_data, test_data2, K)\n",
    "\n",
    "print(\"Predicted Salary for Candidate (a):\", prediction1)\n",
    "print(\"Predicted Salary for Candidate (b):\", prediction2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for unseen data: [1, 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt, pi, exp\n",
    "\n",
    "def split_data(data, test_size=0.2):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_size)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "def calculate_prior(data):\n",
    "    classes = np.unique(data['Selection'])\n",
    "    total_count = len(data)\n",
    "    priors = {}\n",
    "    for cls in classes:\n",
    "        priors[cls] = len(data[data['Selection'] == cls]) / total_count\n",
    "    return priors\n",
    "\n",
    "def calculate_likelihood(data, feature_name, feature_val, label):\n",
    "    filtered_data = data[data['Selection'] == label]\n",
    "    mean, std = filtered_data[feature_name].mean(), filtered_data[feature_name].std()\n",
    "    exponent = exp(-((feature_val - mean) ** 2 / (2 * std ** 2)))\n",
    "    return (1 / (sqrt(2 * pi) * std)) * exponent\n",
    "\n",
    "def classify(data, priors, row):\n",
    "    classes = np.unique(data['Selection'])\n",
    "    probabilities = {}\n",
    "    for cls in classes:\n",
    "        probabilities[cls] = priors[cls]\n",
    "        for index in range(len(row)-1):  # last index is the target class\n",
    "            probabilities[cls] *= calculate_likelihood(data, data.columns[index], row[index], cls)\n",
    "    return max(probabilities, key=probabilities.get)\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(r'C:\\MyFiles\\Notes\\4th Semester\\UCS411 - Artificial Intelligence\\Lab Assignments\\lab\\HR_Selection_Dataset.csv')\n",
    "\n",
    "# Split data\n",
    "train_data, test_data = split_data(data, test_size=0.2)\n",
    "\n",
    "# Calculate prior probabilities\n",
    "priors = calculate_prior(train_data)\n",
    "\n",
    "# Classify unseen data\n",
    "unseen_data = [\n",
    "    [90, 5, 8, 10],  # Candidate (a)\n",
    "    [75, 8, 7, 6]   # Candidate (b)\n",
    "]\n",
    "\n",
    "predictions = [classify(train_data, priors, row) for row in unseen_data]\n",
    "print(\"Predictions for unseen data:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionNode:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "def entropy(y):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    return -np.sum(probabilities * np.log2(probabilities + 1e-15))\n",
    "\n",
    "def information_gain(X, y, feature_index, threshold):\n",
    "    parent_entropy = entropy(y)\n",
    "    left_indices = X[:, feature_index] < threshold\n",
    "    right_indices = ~left_indices\n",
    "    n = len(y)\n",
    "    n_left, n_right = np.sum(left_indices), np.sum(right_indices)\n",
    "    if n_left == 0 or n_right == 0:\n",
    "        return 0\n",
    "    e_left, e_right = entropy(y[left_indices]), entropy(y[right_indices])\n",
    "    n_left, n_right = len(y[left_indices]), len(y[right_indices])\n",
    "    weighted_entropy = (n_left / n) * e_left + (n_right / n) * e_right\n",
    "    return parent_entropy - weighted_entropy\n",
    "\n",
    "def best_split(X, y):\n",
    "    best_gain = 0\n",
    "    split = None\n",
    "    n_features = X.shape[1]\n",
    "    for feature_index in range(n_features):\n",
    "        thresholds = np.unique(X[:, feature_index])\n",
    "        for threshold in thresholds:\n",
    "            gain = information_gain(X, y, feature_index, threshold)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                split = (feature_index, threshold)\n",
    "    return split\n",
    "\n",
    "def build_tree(X, y, depth=0, max_depth=None, min_samples_split=2):\n",
    "    num_samples, num_features = X.shape\n",
    "    if num_samples >= min_samples_split and (max_depth is None or depth < max_depth):\n",
    "        split = best_split(X, y)\n",
    "        if split is not None:\n",
    "            feature, threshold = split\n",
    "            left_indices = X[:, feature] < threshold\n",
    "            right_indices = ~left_indices\n",
    "            left_subtree = build_tree(X[left_indices], y[left_indices], depth+1, max_depth, min_samples_split)\n",
    "            right_subtree = build_tree(X[right_indices], y[right_indices], depth+1, max_depth, min_samples_split)\n",
    "            return DecisionNode(feature, threshold, left_subtree, right_subtree)\n",
    "    return DecisionNode(value=np.bincount(y).argmax())\n",
    "\n",
    "def predict(node, x):\n",
    "    while node.value is None:\n",
    "        if x[node.feature] < node.threshold:\n",
    "            node = node.left\n",
    "        else:\n",
    "            node = node.right\n",
    "    return node.value\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "# Example usage with the Iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split data manually for simplicity in this example\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(X))\n",
    "split_index = int(len(X) * 0.8)\n",
    "train_indices, test_indices = indices[:split_index], indices[split_index:]\n",
    "X_train, X_test = X[train_indices], X[test_indices]\n",
    "y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "# Build the decision tree\n",
    "tree = build_tree(X_train, y_train, max_depth=3, min_samples_split=4)\n",
    "\n",
    "# Predictions\n",
    "y_pred = [predict(tree, xi) for xi in X_test]\n",
    "print(\"Accuracy:\", accuracy(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 128\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Example data loading\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# X_train, X_test, y_train, y_test = your_data_loading_function()\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Run evaluation\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Save results to CSV\u001b[39;00m\n\u001b[0;32m    131\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[12], line 117\u001b[0m, in \u001b[0;36mevaluate_models\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m max_depth \u001b[38;5;129;01min\u001b[39;00m dt_params:\n\u001b[0;32m    116\u001b[0m     model \u001b[38;5;241m=\u001b[39m DecisionTree(max_depth\u001b[38;5;241m=\u001b[39mmax_depth)\n\u001b[1;32m--> 117\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m    119\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m (y_pred \u001b[38;5;241m==\u001b[39m y_test)\u001b[38;5;241m.\u001b[39mmean()\n",
      "Cell \u001b[1;32mIn[12], line 31\u001b[0m, in \u001b[0;36mDecisionTree.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grow_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 41\u001b[0m, in \u001b[0;36mDecisionTree._grow_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m     38\u001b[0m predicted_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(num_samples_per_class)\n\u001b[0;32m     39\u001b[0m node \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleaf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: predicted_class}\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_depth\u001b[49m:\n\u001b[0;32m     42\u001b[0m     idx, thr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_split(X, y)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.array([self._predict(x) for x in X])\n",
    "        return y_pred\n",
    "\n",
    "    def _predict(self, x):\n",
    "        # Compute the Euclidean distance between x and all examples in the training set\n",
    "        distances = np.linalg.norm(self.X_train - x, axis=1)\n",
    "        # Get the indices of the k nearest samples\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = self.y_train[k_indices]\n",
    "        # Majority vote, most common class label\n",
    "        most_common = np.bincount(k_nearest_labels).argmax()\n",
    "        return most_common\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=5):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree_ = self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(inputs, self.tree_) for inputs in X])\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples_per_class = [np.sum(y == i) for i in np.unique(y)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = {'type': 'leaf', 'class': predicted_class}\n",
    "\n",
    "        if depth < self.max_depth:\n",
    "            idx, thr = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] < thr\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node['type'] = 'node'\n",
    "                node['index'] = idx\n",
    "                node['threshold'] = thr\n",
    "                node['left'] = self._grow_tree(X_left, y_left, depth + 1)\n",
    "                node['right'] = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        m, n = X.shape\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        num_parent = [np.sum(y == c) for c in range(len(set(y)))]\n",
    "        best_gini = 1.0 - sum((np.sum(y == c) / m) ** 2 for c in range(len(set(y))))\n",
    "        best_idx, best_thr = None, None\n",
    "\n",
    "        for idx in range(n):\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "            num_left = [0] * len(num_parent)\n",
    "            num_right = num_parent.copy()\n",
    "            for i in range(1, m):\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                gini_left = 1.0 - sum((num_left[x] / i) ** 2 for x in range(len(num_parent)))\n",
    "                gini_right = 1.0 - sum((num_right[x] / (m - i)) ** 2 for x in range(len(num_parent)))\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx, best_thr = idx, (thresholds[i] + thresholds[i - 1]) / 2\n",
    "        return best_idx, best_thr\n",
    "\n",
    "    def _predict(self, inputs, node):\n",
    "        if node['type'] == 'leaf':\n",
    "            return node['class']\n",
    "        if inputs[node['index']] < node['threshold']:\n",
    "            return self._predict(inputs, node['left'])\n",
    "        return self._predict(inputs, node['right'])\n",
    "\n",
    "# Add GaussianNaiveBayes class and data loading here as previously defined\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_models(X_train, X_test, y_train, y_test):\n",
    "    results = []\n",
    "    \n",
    "    # Define models and parameters\n",
    "    knn_params = [1, 3, 5]\n",
    "    nb_params = [GaussianNaiveBayes()]  # Assuming only one configuration for simplicity\n",
    "    dt_params = [None, 3, 5]  # Decision tree depths\n",
    "\n",
    "    # KNN Model Evaluation\n",
    "    for k in knn_params:\n",
    "        model = KNN(k=k)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = (y_pred == y_test).mean()\n",
    "        results.append(['KNN', k, accuracy])\n",
    "\n",
    "    # Naive Bayes Model Evaluation\n",
    "    for model in nb_params:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = (y_pred == y_test).mean()\n",
    "        results.append(['Naive Bayes', 'default', accuracy])\n",
    "\n",
    "    # Decision Tree Model Evaluation\n",
    "    for max_depth in dt_params:\n",
    "        model = DecisionTree(max_depth=max_depth)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = (y_pred == y_test).mean()\n",
    "        results.append(['Decision Tree', max_depth, accuracy])\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example data loading\n",
    "# X_train, X_test, y_train, y_test = your_data_loading_function()\n",
    "\n",
    "# Run evaluation\n",
    "results = evaluate_models(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'Parameter', 'Accuracy'])\n",
    "results_df.to_csv('model_comparisons.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
